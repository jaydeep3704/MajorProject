{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Transcript to Chapter Converter - Dataset Preparation\n",
    "\n",
    "This notebook prepares training data for fine-tuning an LLM to convert YouTube transcripts into chapters.\n",
    "\n",
    "## What we'll do:\n",
    "1. Fetch transcripts from FreeCodeCamp videos using yt-dlp\n",
    "2. Extract existing chapters from video descriptions\n",
    "3. Format data for LoRA/QLoRA fine-tuning\n",
    "4. Save in JSONL format for training\n",
    "\n",
    "## Fine-tuning Format:\n",
    "We'll use the **instruction-following format** which works with most LLMs:\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Convert this YouTube transcript into chapters with timestamps.\",\n",
    "  \"input\": \"<full transcript>\",\n",
    "  \"output\": \"<chapters with timestamps>\"\n",
    "}\n",
    "```\n",
    "\n",
    "## RTX 3050 Compatibility:\n",
    "âœ… **LoRA/QLoRA fine-tuning is possible** on RTX 3050 (4-8GB VRAM)\n",
    "- Use 4-bit quantization (QLoRA)\n",
    "- Recommended models: Mistral-7B, Llama-3-8B, Phi-3\n",
    "- Batch size: 1-2\n",
    "- Gradient accumulation: 4-8 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages\n",
    "\n",
    "First, let's create a requirements.txt file with all necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import yt_dlp\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: dataset\n",
      "Maximum videos to process: 100\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CHANNEL_URL = \"https://www.youtube.com/@freecodecamp/videos\"\n",
    "OUTPUT_DIR = Path(\"./dataset\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Number of videos to process (set to 100 or adjust as needed)\n",
    "MAX_VIDEOS = 100\n",
    "\n",
    "# Minimum transcript length (to filter out very short videos)\n",
    "MIN_TRANSCRIPT_LENGTH = 1000  # characters\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Maximum videos to process: {MAX_VIDEOS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"Extract video ID from YouTube URL.\"\"\"\n",
    "    pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def seconds_to_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to timestamp format (HH:MM:SS or MM:SS).\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    \n",
    "    if hours > 0:\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "    else:\n",
    "        return f\"{minutes:02d}:{secs:02d}\"\n",
    "\n",
    "def parse_timestamp(timestamp: str) -> Optional[int]:\n",
    "    \"\"\"Parse timestamp string to seconds.\"\"\"\n",
    "    try:\n",
    "        # Remove any non-digit/colon characters\n",
    "        timestamp = re.sub(r'[^0-9:]', '', timestamp.strip())\n",
    "        parts = timestamp.split(':')\n",
    "        \n",
    "        if len(parts) == 2:  # MM:SS\n",
    "            return int(parts[0]) * 60 + int(parts[1])\n",
    "        elif len(parts) == 3:  # HH:MM:SS\n",
    "            return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_chapters_from_description(description: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Extract chapter information from video description.\"\"\"\n",
    "    chapters = []\n",
    "    \n",
    "    # Common patterns for chapters in descriptions\n",
    "    patterns = [\n",
    "        r'(\\d{1,2}:\\d{2}(?::\\d{2})?)\\s*[-â€“â€”]?\\s*(.+?)(?=\\n|$)',  # 00:00 - Chapter Name\n",
    "        r'(\\d{1,2}:\\d{2}(?::\\d{2})?)\\s+(.+?)(?=\\n|$)',  # 00:00 Chapter Name\n",
    "        r'\\((\\d{1,2}:\\d{2}(?::\\d{2})?)\\)\\s*(.+?)(?=\\n|$)',  # (00:00) Chapter Name\n",
    "        r'\\[(\\d{1,2}:\\d{2}(?::\\d{2})?)\\]\\s*(.+?)(?=\\n|$)',  # [00:00] Chapter Name\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, description, re.MULTILINE)\n",
    "        if matches:\n",
    "            for timestamp, title in matches:\n",
    "                seconds = parse_timestamp(timestamp)\n",
    "                if seconds is not None:\n",
    "                    chapters.append({\n",
    "                        'timestamp': timestamp,\n",
    "                        'seconds': seconds,\n",
    "                        'title': title.strip()\n",
    "                    })\n",
    "            break  # Use the first pattern that matches\n",
    "    \n",
    "    # Sort by seconds and remove duplicates\n",
    "    chapters = sorted(chapters, key=lambda x: x['seconds'])\n",
    "    return chapters\n",
    "\n",
    "print(\"Utility functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fetch FreeCodeCamp Video URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching FreeCodeCamp videos...\n",
      "Fetching videos from: https://www.youtube.com/@freecodecamp/videos\n",
      "Found 100 videos\n",
      "\n",
      "First 5 videos:\n",
      "1. Relational Database Design â€“ Full Course\n",
      "2. Let's Build Pipeline Parallelism from Scratch â€“ Tutorial\n",
      "3. How to stay curious as a dev in the AI hype era with Sumit Saha [Podcast #205]\n",
      "4. RAG & MCP Fundamentals â€“ A Hands-On Crash Course\n",
      "5. Learn Dynamic Programming with Animations â€“ Full Course for Beginners\n"
     ]
    }
   ],
   "source": [
    "def get_channel_videos(channel_url: str, max_videos: int = 100) -> List[Dict]:\n",
    "    \"\"\"Fetch video information from a YouTube channel.\"\"\"\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'extract_flat': True,\n",
    "        'playlistend': max_videos,\n",
    "        'skip_download': True,\n",
    "    }\n",
    "    \n",
    "    videos = []\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(f\"Fetching videos from: {channel_url}\")\n",
    "            info = ydl.extract_info(channel_url, download=False)\n",
    "            \n",
    "            if 'entries' in info:\n",
    "                for entry in info['entries'][:max_videos]:\n",
    "                    if entry:\n",
    "                        videos.append({\n",
    "                            'video_id': entry.get('id'),\n",
    "                            'title': entry.get('title'),\n",
    "                            'url': f\"https://www.youtube.com/watch?v={entry.get('id')}\"\n",
    "                        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching channel videos: {e}\")\n",
    "    \n",
    "    return videos\n",
    "\n",
    "# Fetch video URLs\n",
    "print(\"Fetching FreeCodeCamp videos...\")\n",
    "videos = get_channel_videos(CHANNEL_URL, MAX_VIDEOS)\n",
    "print(f\"Found {len(videos)} videos\")\n",
    "\n",
    "# Display first few videos\n",
    "if videos:\n",
    "    print(\"\\nFirst 5 videos:\")\n",
    "    for i, video in enumerate(videos[:5], 1):\n",
    "        print(f\"{i}. {video['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fetch Transcripts and Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.request\n",
    "import yt_dlp\n",
    "from typing import Optional\n",
    "\n",
    "def get_transcript(video_id: str, retries: int = 3, base_delay: float = 2.0) -> Optional[str]:\n",
    "    \"\"\"Fetch transcript for a video using yt-dlp (with retry & backoff).\"\"\"\n",
    "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "    ydl_opts = {\n",
    "        'writesubtitles': True,\n",
    "        'writeautomaticsub': True,\n",
    "        'subtitleslangs': ['en'],\n",
    "        'skip_download': True,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "        subtitles = info.get('subtitles', {})\n",
    "        automatic_captions = info.get('automatic_captions', {})\n",
    "\n",
    "        if 'en' in subtitles:\n",
    "            subtitle_data = subtitles['en']\n",
    "        elif 'en' in automatic_captions:\n",
    "            subtitle_data = automatic_captions['en']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        json3_url = None\n",
    "        for fmt in subtitle_data:\n",
    "            if fmt.get('ext') == 'json3':\n",
    "                json3_url = fmt.get('url')\n",
    "                break\n",
    "\n",
    "        if not json3_url:\n",
    "            return None\n",
    "\n",
    "        # ---- RETRY + BACKOFF HERE (important) ----\n",
    "        data = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                with urllib.request.urlopen(json3_url) as response:\n",
    "                    data = json.loads(response.read().decode('utf-8'))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e):\n",
    "                    delay = base_delay * (2 ** attempt)\n",
    "                    print(f\"429 on captions for {video_id}, retrying in {delay:.1f}s\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        if not data:\n",
    "            return None\n",
    "\n",
    "        # ---- Parse transcript ----\n",
    "        full_transcript = \"\"\n",
    "\n",
    "        for event in data.get('events', []):\n",
    "            if 'segs' not in event:\n",
    "                continue\n",
    "\n",
    "            start_time = event.get('tStartMs', 0) / 1000\n",
    "            timestamp = seconds_to_timestamp(start_time)\n",
    "\n",
    "            text = ''.join(\n",
    "                seg.get('utf8', '') for seg in event['segs']\n",
    "            ).strip().replace('\\n', ' ')\n",
    "\n",
    "            if text:\n",
    "                full_transcript += f\"[{timestamp}] {text}\\n\"\n",
    "\n",
    "        return full_transcript.strip() if full_transcript else None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching transcript for {video_id}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(video_url: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    Extract video metadata using yt-dlp.\n",
    "    Provides chapters, description, title, duration.\n",
    "    \"\"\"\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"skip_download\": True,\n",
    "        \"no_warnings\": True,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "        if not info:\n",
    "            return None\n",
    "\n",
    "        metadata = {\n",
    "            \"id\": info.get(\"id\"),\n",
    "            \"title\": info.get(\"title\"),\n",
    "            \"description\": info.get(\"description\", \"\"),\n",
    "            \"duration\": info.get(\"duration\"),\n",
    "            \"chapters\": []\n",
    "        }\n",
    "\n",
    "        # Preferred: yt-dlp native chapters\n",
    "        if info.get(\"chapters\"):\n",
    "            for ch in info[\"chapters\"]:\n",
    "                metadata[\"chapters\"].append({\n",
    "                    \"start_time\": ch.get(\"start_time\", 0),\n",
    "                    \"end_time\": ch.get(\"end_time\"),\n",
    "                    \"title\": ch.get(\"title\", \"\").strip()\n",
    "                })\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Metadata extraction failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chapters_output(chapters: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Format chapters into:\n",
    "    MM:SS - Title\n",
    "    HH:MM:SS - Title\n",
    "    \"\"\"\n",
    "    if not chapters:\n",
    "        return \"\"\n",
    "\n",
    "    lines = []\n",
    "    for ch in chapters:\n",
    "        timestamp = ch.get(\"timestamp\")\n",
    "        if not timestamp:\n",
    "            timestamp = seconds_to_timestamp(ch.get(\"seconds\", 0))\n",
    "\n",
    "        title = ch.get(\"title\", \"\").strip()\n",
    "        lines.append(f\"{timestamp} - {title}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process Videos and Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video processing...\n",
      "This may take a while depending on the number of videos.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 on captions for 26ls5lNiijk, retrying in 2.0s\n",
      "429 on captions for 26ls5lNiijk, retrying in 4.0s\n",
      "429 on captions for 26ls5lNiijk, retrying in 8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   1%|          | 1/100 [00:18<30:41, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping Relational Database Design â€“ Full Course: Transcript too short or unavailable\n",
      "429 on captions for D5F8kp_azzw, retrying in 2.0s\n",
      "429 on captions for D5F8kp_azzw, retrying in 4.0s\n",
      "429 on captions for D5F8kp_azzw, retrying in 8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   1%|          | 1/100 [00:37<1:01:06, 37.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mget_transcript\u001b[39m\u001b[34m(video_id, retries, base_delay)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson3_url\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     48\u001b[39m         data = json.loads(response.read().decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    562\u001b[39m args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    495\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayde\\miniconda\\envs\\major_project\\Lib\\urllib\\request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 429: Too Many Requests",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting video processing...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThis may take a while depending on the number of videos.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m dataset = \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMIN_TRANSCRIPT_LENGTH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mprocess_videos\u001b[39m\u001b[34m(videos, min_length)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Get transcript\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Prevent burst rate-limiting BEFORE transcript fetch\u001b[39;00m\n\u001b[32m     14\u001b[39m time.sleep(\u001b[32m1.2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m transcript = \u001b[43mget_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transcript \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(transcript) < min_length:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Transcript too short or unavailable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mget_transcript\u001b[39m\u001b[34m(video_id, retries, base_delay)\u001b[39m\n\u001b[32m     52\u001b[39m     delay = base_delay * (\u001b[32m2\u001b[39m ** attempt)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m429 on captions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def process_videos(videos: List[Dict], min_length: int = 1000) -> List[Dict]:\n",
    "    dataset = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for video in tqdm(videos, desc=\"Processing videos\"):\n",
    "        try:\n",
    "            video_id = video['video_id']\n",
    "            video_url = video['url']\n",
    "\n",
    "            # ðŸ”¥ VERY strong throttle (30â€“40 seconds)\n",
    "            sleep_time = random.uniform(30, 40)\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "            transcript = get_transcript(video_id)\n",
    "            if not transcript or len(transcript) < min_length:\n",
    "                print(f\"\\nSkipping {video['title']}: Transcript too short or unavailable\")\n",
    "                failed += 1\n",
    "                continue\n",
    "\n",
    "            metadata = get_video_metadata(video_url)\n",
    "            if not metadata:\n",
    "                failed += 1\n",
    "                continue\n",
    "\n",
    "            chapters = []\n",
    "\n",
    "            if metadata.get('chapters'):\n",
    "                for ch in metadata['chapters']:\n",
    "                    chapters.append({\n",
    "                        'timestamp': seconds_to_timestamp(ch.get('start_time', 0)),\n",
    "                        'seconds': ch.get('start_time', 0),\n",
    "                        'title': ch.get('title', '')\n",
    "                    })\n",
    "\n",
    "            if not chapters and metadata.get('description'):\n",
    "                chapters = extract_chapters_from_description(metadata['description'])\n",
    "\n",
    "            if not chapters or len(chapters) < 2:\n",
    "                print(f\"\\nSkipping {video['title']}: No chapters found\")\n",
    "                failed += 1\n",
    "                continue\n",
    "\n",
    "            chapters_output = format_chapters_output(chapters)\n",
    "\n",
    "            dataset.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"video_title\": video['title'],\n",
    "                \"instruction\": (\n",
    "                    \"Convert the following YouTube video transcript into chapters \"\n",
    "                    \"with timestamps. Each chapter should have a timestamp in \"\n",
    "                    \"MM:SS or HH:MM:SS format followed by a descriptive title.\"\n",
    "                ),\n",
    "                \"input\": transcript,\n",
    "                \"output\": chapters_output,\n",
    "                \"num_chapters\": len(chapters),\n",
    "                \"transcript_length\": len(transcript)\n",
    "            })\n",
    "\n",
    "            successful += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {video['title']}: {e}\")\n",
    "            failed += 1\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Process all videos\n",
    "print(\"Starting video processing...\")\n",
    "print(\"This may take a while depending on the number of videos.\\n\")\n",
    "dataset = process_videos(videos, MIN_TRANSCRIPT_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset:\n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"Total examples: {len(dataset)}\")\n",
    "    print(f\"\\nTranscript length statistics:\")\n",
    "    \n",
    "    transcript_lengths = [ex['transcript_length'] for ex in dataset]\n",
    "    print(f\"  Min: {min(transcript_lengths):,} characters\")\n",
    "    print(f\"  Max: {max(transcript_lengths):,} characters\")\n",
    "    print(f\"  Average: {sum(transcript_lengths) // len(transcript_lengths):,} characters\")\n",
    "    \n",
    "    chapter_counts = [ex['num_chapters'] for ex in dataset]\n",
    "    print(f\"\\nChapter count statistics:\")\n",
    "    print(f\"  Min: {min(chapter_counts)} chapters\")\n",
    "    print(f\"  Max: {max(chapter_counts)} chapters\")\n",
    "    print(f\"  Average: {sum(chapter_counts) / len(chapter_counts):.1f} chapters\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Sample Training Example:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\nVideo: {sample['video_title']}\")\n",
    "    print(f\"\\nInstruction:\\n{sample['instruction']}\")\n",
    "    print(f\"\\nInput (first 500 chars):\\n{sample['input'][:500]}...\")\n",
    "    print(f\"\\nOutput:\\n{sample['output']}\")\n",
    "else:\n",
    "    print(\"No data in dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Dataset in Multiple Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset:\n",
    "    # 1. Save as JSONL (for LoRA training with libraries like Axolotl, LLaMA Factory)\n",
    "    jsonl_path = OUTPUT_DIR / \"training_data.jsonl\"\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for example in dataset:\n",
    "            # Format for instruction fine-tuning\n",
    "            training_format = {\n",
    "                \"instruction\": example['instruction'],\n",
    "                \"input\": example['input'],\n",
    "                \"output\": example['output']\n",
    "            }\n",
    "            f.write(json.dumps(training_format, ensure_ascii=False) + '\\n')\n",
    "    print(f\"âœ“ Saved JSONL format: {jsonl_path}\")\n",
    "    \n",
    "    # 2. Save as JSON (complete dataset with metadata)\n",
    "    json_path = OUTPUT_DIR / \"training_data_full.json\"\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ“ Saved full JSON format: {json_path}\")\n",
    "    \n",
    "    # 3. Save as CSV (for analysis)\n",
    "    csv_data = []\n",
    "    for ex in dataset:\n",
    "        csv_data.append({\n",
    "            'video_id': ex['video_id'],\n",
    "            'video_title': ex['video_title'],\n",
    "            'num_chapters': ex['num_chapters'],\n",
    "            'transcript_length': ex['transcript_length']\n",
    "        })\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    csv_path = OUTPUT_DIR / \"dataset_metadata.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"âœ“ Saved metadata CSV: {csv_path}\")\n",
    "    \n",
    "    # 4. Save as Alpaca format (alternative format for some trainers)\n",
    "    alpaca_data = []\n",
    "    for ex in dataset:\n",
    "        alpaca_data.append({\n",
    "            \"instruction\": ex['instruction'],\n",
    "            \"input\": ex['input'],\n",
    "            \"output\": ex['output']\n",
    "        })\n",
    "    alpaca_path = OUTPUT_DIR / \"training_data_alpaca.json\"\n",
    "    with open(alpaca_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(alpaca_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ“ Saved Alpaca format: {alpaca_path}\")\n",
    "    \n",
    "    # 5. Save training/validation split (80/20)\n",
    "    split_idx = int(len(dataset) * 0.8)\n",
    "    train_data = dataset[:split_idx]\n",
    "    val_data = dataset[split_idx:]\n",
    "    \n",
    "    train_path = OUTPUT_DIR / \"train.jsonl\"\n",
    "    with open(train_path, 'w', encoding='utf-8') as f:\n",
    "        for example in train_data:\n",
    "            training_format = {\n",
    "                \"instruction\": example['instruction'],\n",
    "                \"input\": example['input'],\n",
    "                \"output\": example['output']\n",
    "            }\n",
    "            f.write(json.dumps(training_format, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    val_path = OUTPUT_DIR / \"validation.jsonl\"\n",
    "    with open(val_path, 'w', encoding='utf-8') as f:\n",
    "        for example in val_data:\n",
    "            training_format = {\n",
    "                \"instruction\": example['instruction'],\n",
    "                \"input\": example['input'],\n",
    "                \"output\": example['output']\n",
    "            }\n",
    "            f.write(json.dumps(training_format, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"âœ“ Saved training split: {train_path} ({len(train_data)} examples)\")\n",
    "    print(f\"âœ“ Saved validation split: {val_path} ({len(val_data)} examples)\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Dataset preparation complete!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAll files saved in: {OUTPUT_DIR}\")\n",
    "    print(f\"\\nReady for fine-tuning with LoRA/QLoRA on your RTX 3050!\")\n",
    "else:\n",
    "    print(\"No dataset to save!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generate Training Configuration\n",
    "\n",
    "Create a configuration file for training with popular frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training config for Axolotl (popular LoRA training framework)\n",
    "axolotl_config = {\n",
    "    \"base_model\": \"mistralai/Mistral-7B-v0.1\",\n",
    "    \"model_type\": \"MistralForCausalLM\",\n",
    "    \"tokenizer_type\": \"LlamaTokenizer\",\n",
    "    \"load_in_8bit\": False,\n",
    "    \"load_in_4bit\": True,\n",
    "    \"strict\": False,\n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"path\": \"train.jsonl\",\n",
    "            \"type\": \"alpaca\"\n",
    "        }\n",
    "    ],\n",
    "    \"val_set_size\": 0.05,\n",
    "    \"output_dir\": \"./youtube-chapter-lora\",\n",
    "    \"adapter\": \"lora\",\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"lora_target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    \"sequence_len\": 2048,\n",
    "    \"sample_packing\": True,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"micro_batch_size\": 1,\n",
    "    \"num_epochs\": 3,\n",
    "    \"optimizer\": \"adamw_torch\",\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"train_on_inputs\": False,\n",
    "    \"group_by_length\": False,\n",
    "    \"bf16\": False,\n",
    "    \"fp16\": True,\n",
    "    \"tf32\": False,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"logging_steps\": 1,\n",
    "    \"save_steps\": 100,\n",
    "    \"eval_steps\": 100,\n",
    "    \"warmup_steps\": 10,\n",
    "    \"weight_decay\": 0.01\n",
    "}\n",
    "\n",
    "config_path = OUTPUT_DIR / \"axolotl_config.yml\"\n",
    "import yaml\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(axolotl_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ“ Saved Axolotl training config: {config_path}\")\n",
    "\n",
    "# Generate a simple training script\n",
    "training_script = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simple LoRA Fine-tuning Script for RTX 3050\n",
    "Using transformers + PEFT (Parameter-Efficient Fine-Tuning)\n",
    "\"\"\"\n",
    "\n",
    "# Install required packages first:\n",
    "# pip install transformers peft bitsandbytes accelerate datasets torch\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"  # or \"meta-llama/Llama-3-8B\"\n",
    "DATASET_PATH = \"./dataset/train.jsonl\"\n",
    "OUTPUT_DIR = \"./youtube-chapter-model\"\n",
    "\n",
    "# 4-bit quantization config for RTX 3050\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load model with 4-bit quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=32,  # LoRA alpha\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Load and prepare dataset\n",
    "dataset = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n",
    "\n",
    "def format_prompt(example):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Input:\n",
    "{example['input']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\"\"\"\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "dataset = dataset.map(format_prompt)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=2048,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training arguments optimized for RTX 3050\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,  # Small batch size for 4GB VRAM\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    warmup_steps=50,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\"\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"Model saved to {OUTPUT_DIR}\")\n",
    "'''\n",
    "\n",
    "script_path = OUTPUT_DIR / \"train_lora.py\"\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(training_script)\n",
    "\n",
    "print(f\"âœ“ Saved training script: {script_path}\")\n",
    "print(f\"\\nTo start training, run: python {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Create README with Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_content = '''# YouTube Transcript to Chapter Converter - Fine-tuning Dataset\n",
    "\n",
    "This dataset contains YouTube video transcripts and their corresponding chapters from FreeCodeCamp videos.\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "Each training example contains:\n",
    "- `instruction`: Task description for the model\n",
    "- `input`: Full video transcript with timestamps\n",
    "- `output`: Chapter titles with timestamps\n",
    "\n",
    "## Files\n",
    "\n",
    "- `training_data.jsonl`: Main training data in JSONL format\n",
    "- `train.jsonl`: Training split (80%)\n",
    "- `validation.jsonl`: Validation split (20%)\n",
    "- `training_data_alpaca.json`: Alpaca format\n",
    "- `training_data_full.json`: Complete dataset with metadata\n",
    "- `dataset_metadata.csv`: Summary statistics\n",
    "- `axolotl_config.yml`: Configuration for Axolotl framework\n",
    "- `train_lora.py`: Simple training script\n",
    "\n",
    "## Training on RTX 3050\n",
    "\n",
    "Your RTX 3050 (4-8GB VRAM) can handle LoRA fine-tuning with these optimizations:\n",
    "\n",
    "### Requirements\n",
    "\n",
    "```bash\n",
    "pip install transformers peft bitsandbytes accelerate datasets torch\n",
    "```\n",
    "\n",
    "### Option 1: Using the Provided Script\n",
    "\n",
    "```bash\n",
    "python train_lora.py\n",
    "```\n",
    "\n",
    "### Option 2: Using Axolotl\n",
    "\n",
    "```bash\n",
    "# Install Axolotl\n",
    "git clone https://github.com/OpenAccess-AI-Collective/axolotl\n",
    "cd axolotl\n",
    "pip install -e .\n",
    "\n",
    "# Copy your data and config\n",
    "cp path/to/dataset/* axolotl/\n",
    "\n",
    "# Start training\n",
    "accelerate launch -m axolotl.cli.train axolotl_config.yml\n",
    "```\n",
    "\n",
    "### Option 3: Using Ollama (for inference after training)\n",
    "\n",
    "After training, you can convert your model to GGUF format and use with Ollama:\n",
    "\n",
    "```bash\n",
    "# Convert to GGUF\n",
    "python llama.cpp/convert.py ./youtube-chapter-model --outfile model.gguf\n",
    "\n",
    "# Create Modelfile\n",
    "FROM ./model.gguf\n",
    "PARAMETER temperature 0.7\n",
    "PARAMETER top_p 0.9\n",
    "\n",
    "# Import to Ollama\n",
    "ollama create youtube-chapter-converter -f Modelfile\n",
    "```\n",
    "\n",
    "## Recommended Models for RTX 3050\n",
    "\n",
    "1. **Mistral-7B** (Recommended)\n",
    "   - Best performance for size\n",
    "   - ~4GB VRAM with 4-bit quantization\n",
    "\n",
    "2. **Llama-3-8B**\n",
    "   - Excellent instruction following\n",
    "   - ~4GB VRAM with 4-bit quantization\n",
    "\n",
    "3. **Phi-3-mini**\n",
    "   - Smaller, faster\n",
    "   - ~2GB VRAM with 4-bit quantization\n",
    "\n",
    "## Training Parameters (Optimized for RTX 3050)\n",
    "\n",
    "```python\n",
    "- Batch size: 1\n",
    "- Gradient accumulation: 8 steps\n",
    "- Learning rate: 2e-4\n",
    "- LoRA rank: 16\n",
    "- LoRA alpha: 32\n",
    "- 4-bit quantization: Enabled\n",
    "- Gradient checkpointing: Enabled\n",
    "- FP16 training: Enabled\n",
    "```\n",
    "\n",
    "## Expected Training Time\n",
    "\n",
    "- ~2-4 hours for 50 examples on RTX 3050\n",
    "- ~4-8 hours for 100 examples\n",
    "\n",
    "## Using the Trained Model\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load LoRA adapters\n",
    "model = PeftModel.from_pretrained(base_model, \"./youtube-chapter-model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./youtube-chapter-model\")\n",
    "\n",
    "# Generate chapters\n",
    "prompt = f\"\"\"### Instruction:\n",
    "Convert the following YouTube video transcript into chapters with timestamps.\n",
    "\n",
    "### Input:\n",
    "{your_transcript}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "chapters = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(chapters)\n",
    "```\n",
    "\n",
    "## Tips for Better Results\n",
    "\n",
    "1. **More data**: Try to get 200-500 examples for better performance\n",
    "2. **Diverse videos**: Include various video lengths and topics\n",
    "3. **Quality filtering**: Remove low-quality transcripts\n",
    "4. **Augmentation**: Create variations of existing examples\n",
    "5. **Validation**: Always check model outputs on validation set\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory Errors\n",
    "- Reduce batch size to 1\n",
    "- Increase gradient accumulation steps\n",
    "- Enable gradient checkpointing\n",
    "- Use 4-bit quantization\n",
    "- Reduce sequence length\n",
    "\n",
    "### Slow Training\n",
    "- Use FP16 training\n",
    "- Enable gradient checkpointing\n",
    "- Use paged optimizers (paged_adamw_8bit)\n",
    "- Reduce LoRA rank if needed\n",
    "\n",
    "## License\n",
    "\n",
    "Dataset is for educational purposes. Respect YouTube's Terms of Service and video creators' rights.\n",
    "'''\n",
    "\n",
    "readme_path = OUTPUT_DIR / \"README.md\"\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"âœ“ Saved README: {readme_path}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"All files created successfully!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nDataset directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review the dataset and README\")\n",
    "print(\"2. Install required packages: pip install transformers peft bitsandbytes accelerate\")\n",
    "print(\"3. Run training: python dataset/train_lora.py\")\n",
    "print(\"4. Wait 2-8 hours depending on dataset size\")\n",
    "print(\"5. Test your model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "major_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
